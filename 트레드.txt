1.1 트레드 기초
* 트레드는 CPU 이용의 기본 유닛으로, 트레드ID, PC, 저장세트, 스택으로 구성되어 있다.(다른 트레드들과 같은 프로세스에서 코드 섹션, 데이터 섹션, 다른 OS 요소들을 공유 )

* 한 어플리케이션은 멀티코어 시스템들에서 프로세싱을 수용하는데 이점이 있도록 만들어졌다.
트래드가 유명해기 전에 보통 사용하는 방법은 프로세스 생성이다(멀티프로세스 어플리케이션).
(하지마나 프로세스 생성은 시간 소비와 자원 소비와 관련이 있다.)

* 멀티 트레드 프로그래밍의 장점은 다음처럼 요약될 수 있다 :
 - 반응성 : 상호작용하는 멀티트레디드 어플리케이션은 사용자들에게 심지어 부분이 막히거나 수행하더라도 긴 동작을 하도록 책임될 수 있다.
 - 자원 공유 : 트레드들은 메모리와 자원을 기본적으로 공유하고, 허락된 어플리케이션은 여러 행동하는다른 트레드들을 같은 주소 공간에서 가진다.
 - 경제성 : 프로세스에 할당된 메모리와 자원들은 값이 들지만, 트레드들은 서로의 리소스를 공유한다.
             또한, 문맥 교환이 트레드 안에서가 프로세스 안에서 보다 빠르다.
           (솔라리스에서 예를 들면, 트레드 생성은 프로세스 생성 보다 30배 빠르고, 트레드에서 문맥 교환은 약 5배가 프로세스 안에서보다 빠르다.)

 - 측정성 : 한 프로세스 안에서 다른 트레드는 다른 코어를 가지고서 실행중일 수 있다.


- 멀티코어 프로그래밍
* 최근 컴퓨터 시스템 디자인에서의 트렌드는 복수의 계산 코어들을 하나의 칩에 자리하는 것이다.(예 : 멀티 코어 시스템) 멀티트레디드 프로그래밍은 한 운영체계를 더욱 효과적인 사용을 위해 이런 멀티코어 컴퓨팅 코어들과 향상된 동시성을 제공한다.
현대 멀티코어 시스템들에서 하이퍼 트레딩은 계속해서 여러 컴퓨팅 코어들 사용을 더 좋게 만들기 위해  시스템 디자이너들과 어플리케이션 프로그래머들에게 압력을 가하도록 위치하고 있으며, 일반적으로 프로그래밍에서는 5개의 도전적인 영역이 있다. :
 - 업무 식별 : 따로 그리고 동시 업무로 나눌 수 있는 영역을 찾기 
 - 균형 : 식별된 업무는 같은 가치의 동일한 일을 수행해야 한다.
 - 데이터 조각 : 접속되고 변형된 데이터는 마치 업무 식별 안에서 처럼 나눠져야 한다
 - 데이터 의존 : 만약 업무에 의해 접속된 데이터가 다른 업무에 의존한다면, 이것은 동기화되어져서 데이터 의존도를 받아들여야 한다.
 - 테스트하기와 디버깅 : 프로그램이 동시에 사용하는 중에, 많이 차이나는 실행 경로들은 테스트하거나 디버그 하는 것이 가능하므로 이런 프로그램들은 매우 중요하고 잘 다뤄야 한다.

* 다음은 일반적인 2종류의 동시성이다 :
 - 데이터 동시성 : 다양한 컴퓨팅 코어들에서 데이터의 부분집합 분배하기와 같은 동작을 각 코어에서 수행하기
 - 작업 동시성 : 작업 분배를 다양한 컴퓨팅 코어를 통해서 하고 각 작업은 독특한 수행을 한다.
** 대부분의 인스턴스에서는, 어플리케이션들은 이 두 전략을 같이 하이브리드로 사용한다.


- 멀티트리딩 모델들
* 트레드들을 지원하기는 사용자 레벨(사용자 트레드)이나 커널 레벨(커널 트레드)에서 제공될 수 있다.
사실상 모든 현재 OS를 지원하는 커널 드레드들과 이것은 사용자와 커널 트레드들의 관계를 요구한다.

많은것이 하나에 가는 모델 : 다양한 사용자들의 트레드들은 커널 트레드로 가도록 명령된다.
 - 트레드 관리는 사용자 레벨에서의 트레드 라이브러리에 의해 되고, 이것은 효과적일 뿐 아니라 트레드가 커널 트레드에 단번에 접속할 수 있고(멀티코어 시스템에서 어떤 동시성도 아닌) 프로세스는 만약 트레드가 블로킹 시스템 콜을 만들면 막는다.

하나당 하나 모델 : 각 사용자 트레드의 지도들은 하나의 트레드에 간다
 - 많은 동시성과 멀티코어 시스템에서 평행성을 제공하지만, 커널 트레드를 만들기는 어플리케이션의 수행에 부담이 될 수 있다(많은 트레드들이 보통 제한됨).
 - 리눅스와 윈도우는 이 하나당 하나 모델을 지원한다.

많은것이 많게 하는 모델 : 많은 사용자 레벨 트레드는 작거나 동등한 수의 커널 트레드들에게 다양하게 간다.
 - 어떤 다양화는 2 레벨 모델이고, 이 모델은 많은 사용자 레벨 트레드들이 작거나 동등한 트레드들이 있는 위치 뿐 아니라, 하나의 사용자 레벨의 트레드도 허용해서 커널 트레드 하나의 경계를 만든다.

** 솔라리스 OS는 9버전 이후로 이 모델로 만들어졌지만, 최근 버전에서 하나당 하나 모델을 사용한다.

* 한 트레드 도서관은 프로그래머에게 API를 트레드 생성과 관리를 위해서 제공한다.
도서관은 완전히 사용자 공간이거나 시스템 콜에서 커널공간임
3가지 메인 트레드 도서관은 근래 사용함 :
 - POSIX P트레드 : 종종 UNIX와 리눅스 시스템에서 있음, 사용자 레벨과 커널 레벨 트레드들을 위함
 - 윈도우 트레드 도서관 : 윈도우 OS, 커널 레벨 트레드들(하나당 하나 매핑 모델)
 - 자바 트레드 API들
* 비동기식 트레딩으로, 한번 부모가 자식 트레드를 만들면, 부모는 그것의 실행을 재개해서 부모와 자식이 동시에 실행한다.
* 동기식 트레딩은 나타나는 때는 부모 트레드가 하나 또는 그 이상의 자식을 만들고 나면, 모든 자식들은 이것을 재개하기 전에 종료하기 위해서 멈춰야 한다(이것을 모두 조인하는 전략 이라고 한다).

POSIX(이동가능한 OS 인터페이스) - 동작 시스템 사이에서 적합성 관리를 위한 가족의 기준 
 - 포식스는 API들을 정의한다 선 갑옷들과 유틸리티 인터페이스들을, UNIX의 변종들의 소프트웨어 적합함을 위해


* 더 좋은 지원하기 위한 멀티트레드된 어플리케이션들 디자인은 트레딩의 생성과 관리를 어플리케이션 개발자로 부터 컴플라이어와 런타임 도서관까지 변경한다. 이 전략은 최근 트렌드로 유명하다.
* 우리는 멀티트레드 된 프로그램들을 만들기 위해서 절대적인 트레딩의 3가지 접근을 탐험하고 절대적인 트레딩을 통해 멀티코어 프로세스들의 이점을 얻을 수 있게 된다.


- 트레드 풀들
* 동시 서비스들을 위한 제한되지 않은 트레드들(예, 웹서버 내)은 시스템 자원들이 지칠 수 있고 시스템 오류가 따라온다. 이 문제의 한 해결책은 트레드 풀을 사용하고, 많은 트레드들이 프로세스 시작할 때 만들어지고 일을 받기 위해 풀에서 기다리게 된다.
* 트레드 풀들은 다음의 이점이 있다 :
 존재하는 트레드에서 요구하는 서비스는 트레드를 만들기 위해 기다리는 것 보다 빠르다.
 트레드 풀은 트레드의 수를 한번씩 제한하고 이것은 특별히 중요한데 시스템들에게 중요하고, 큰 숫자의 동시 트레드들은 지원할 수 없다.
 생성한 작업으로부터 작업의 수행을 나누기는 우리가 작업 스케줄링을 위한 다양한 가능한 전략을 사용하는데 허용한다.
* 정교한 트레드 풀 구조는 역동적으로 트레드들의 수를 풀에서 조절하고 사용 패턴을 따라간다(예. 애플의 그랜드 센트럴 디스패치).
* 윈도우 OS는 제공한다 트레드 풀 API들의 세트를
 동기화, 작업, 타이머, I/O, 콜백 환경, 콜백, 그 밖의 것들에 대한 범주
 하나의 작업 카테고리 API들은
 - CreateThreadPoolWork()   - CloseThreadPoolWork()
 - SubmitThreadPoolWork()  - TrySubmitThreadPoolCallback()
 - WaitForThreadPoolWookCallbacks()


- OpenMP

====================================================


8. 동기화 문제 (Synchronization Problem)를 해결하기 위한 방법 중 Mutex와 Semaphore 기법에 대해 비교 설명하시오.

Mutex(세마포)
* 간단한 소프트웨어 툴. 중요한 영역에서의 문제를 해결함
* acquire()와 release() 함수를 사용하는 예제
do {
    [acquire lock]
            critical section
    [release lock]
            remainder section
} while (TRUE);


ACQUIRE : 
   acquire() {
        while (!available)
          ; /* busy wait */
        available = false;;
}

RELEASE :
   release() {
         available = true;
}

두 가지 acquire()와 release() 호출은 자동적으로 수행하게 되어 있다(예, 하드웨어 지원).
이 실행의 주요한 불리한 점은 스핀락으로 잠금이 가능하게 될 때 까지 대기하는 동안 스핀에 의해 바쁘게 대기하는 것이다.
 - CPU 사이클을 낭비하기는 다른 프로세스에게는 유용할지라도
 - 스핀락은 짧은 시간을 대기하는 데 유용하고, 종종 멀티프로세서 시스템들을 활용한다. 멀티프로세서 시스템들은 한 트레드가 하나의 프로세서에서 돌 수 있는 곳이고 다른 트레드는 다른 프로세서에서 그것의 중요한 영역을 수행하는 곳이다.



Semaphores(세마포)
* Mutex(뮤텍스)보다 더 견고한 프로세스 동기화 툴
* 세마포 S는 정수형 변수이고 2개의 기본 동작인 wait()와 signal()에 의해 접속된다.
WAIT :
   wait(s) {
      while s <= 0; // no-op
      s -- ;
}

SIGNAL :
   signal(s) {
       s ++ ;
}
2진수 세마포, S(오직 '0' 또는 '1' 값만 가짐)는 무텍스 잠금과 비슷하게 행동한다
세마포 세기는 S가 정수형 숫자를 가지고, 자원이 최근 사용하는 숫자를 표현한다.
* 한 세마포는 다중화 프로세스를 동기화 연산하는데 사용될 수 있다.
 프로세스 P1에서 문서 S1이 P2의 문서 이전에 실행을 필요로 하는데 이 때, :
 프로세스 P1에서 우리는 다음 코드를 넣는다. {S1; signal(synch);}
 프로세스 P2에서 우리는 세마포 싱크를 0으로 초기화 한 다음 이 코드를 넣는다. {wait(synch); S2; }


뮤텍스 잠금과 세마포
* 바쁜 대기가 없는 세마포 실행(예 : 셀프 블로킹)

세마포 구조 :
 typedef struct {
       int value;
       struct process *list;
} semaphore;

대기 작동 :
 wait(semaphore *S) {
        S-> value--;
        if (S-> value < 0) {
                add this process to S -> list;
                block();
        }
 }

신호 작동 :
 signal(semaphore *S) {
         S-> value++;
         if (S-> value <= 0) {
                  remove a proccess P from S-> list;
                  wakeup(P);
         }
 }

block() : 프로세스를 레디에서 대기 큐로 이동한다
wakeup() : 프로세스를 대기 큐에서 레디 큐로 이동한다

* 세마포 작동 - wait(), signal()은 자동으로 실행된다. : 
 - 개별적 실행을 위한 침투가 불가능하게 하기는 멀티프로세서 환경에 적합하지 않다.
 - 대체 잠금 기능(예 : 스핀락)은 wait()과 signal()이 자동으로 수행되는 것을 확실하게 할 것이 요구된다.


*세마포 사용 중 데드락 문제 :
 -프로세스의 묶음에서 모든 프로세스에 대한 한 이벤트를 위해 대기할 때에 대한 언급은 그 묶음에서 다른 프로세스에 의해 불러올 수 있다.


* 세마포 사용하면서 우선순위 변경문제 :
프로세스들 L(낮은 우선순위), M(보통 우선순위), H(높은 우선순위)에서 우선순위 기반 시스템에서 L, H, M 순서로 나타나고, 만약 프로세스 L과 H이 같은 자원 R(L에 의해 잠금된 자원)을 요구한다면, :
 - 실행하는 프로세스 L은 프로세스 M에 의해서 선점되지만, 반면 H가 자원 R을 기다리는 동안 L에 의해 종료되기 위해 대기한다.
 - 프로세스 L에 대한 H의 우선순위는 H가 시스템에 나타날 때, 이런 우선순위 변경을 피하기 위해서 물려받을 필요가 있다.
** 일시적 스위칭인 이런 타입은 '우선순위 상속 프로토콜'이라고 부른다.

====================================================
4. 5개의 프로세스가 시스템에 입력됨
Time-Sharing 스케줄러의  quantum time이 3이라 할 때, FCFS (First Come First Serve), SJF(Shortest Job First), 그리고 RR(Round-Robin) 스케줄러의 프로세스 실행 순서를 도시하고. 각 방식의 평균 대기 시간(Average Wating Time)을 계산하시오.

사진

====================================================


6. Windows XP OS의 스케줄러 특징을 설명하시오.

* 윈도우즈 스케줄러들은 우선순위기반, 선점 스케줄링 알고리즘을 사용하는 트레드이다.
* 스케줄 분배는 32레벨의 우선순위를 2가지 클래스를 가지고 사용한다. - 리얼타임 클래스(16~31)과 다양화하는 클래스(시작 부터 최대치까지는 1~15)
 - 스케줄 분배는 다음 트레드를 실행하기 위해 그들을 가로지르면서 각 스케줄링 우선순위를 위해 큐를 사용한다.
 - 주어진 우선순위 클래스 속의 트레드는 물론 관련된 우선순위를 갖는다. 예를 들어 쉬고 있거나, 느린, 평균 이하, 평균, 평균 이상 등
 - 프로세스는 전형적인 NORMAL_PRIORITY_CLASS의 멤버이고, 트레드의 최초 우선순위는 전형적인 기본(각 클래스의 '보통'레벨) 우선순위의 트레드에 속해 있는 프로세스이다.
 - API의 SetPriorityClass()의 우선순위 클래스를 변경하고, SetThreadPriority()는 기본 우선순위를 변경하는데 주목한다.
* 다양한 우선순위 클래스에 있는 트레드는 그것의 시간의 양자(CPU 영역의 트레드 관련), 그것의 우선순위는 계산 영역의 CPU 소비를 제한하기 위해 낮아진다.
* 전면('움직이는' 창)의 진행은 그들의 스케줄링 양자들이 3배(실행하려는 3배 긴 양자) 다양해지는데, 이는 전면에서 상호작용하는 프로세스들에게 나아진 응답을 주기 위해서이다.

====================================================


7. Pre-emptive OS 시스템에서 race condition에 의한 동기화 문제에 대해 설명하고, 이를 해결하기 위한 ciritical section에 대해 설명하시오 (Critical Section의 요구조건 3가지에 대한 설명 포함)

