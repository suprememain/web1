

1. Microsoft Win32 응용에서 사용할 수 있는 Thread 생성 함수 3가지의 원형과 입력/출력 파라미터를 설명하고 그 차이를 기술

-IA-32 Architecture
* The memory management of IA-32 incorporates segmentation as well as paging scheme

[CPU] -logical address-> [segmentation unit] -linear address-> [paging unit] -physical address-> [physical memory]

 . Segmentation Unit: 16-bits selector with 32- bits offset of logical address structure (48 bits in total)
 - selector comprises of 13-bit segment (8K segment items can be designated),
  1-bit table indicator (one for GDT - Global Descriptor Table - for shared segments, and the other one for LDT - Local Descriptor Table - for private segments of a process), and 2-bits protection
 - 16-bits selector can accomodate 16K number of segments in total (8K for global and 8K for local),
  each of which is of the size 4GB (32 bits offset)
 - based on the descriptor table indexed by the selector, 32-bits linear address is generated.

 . Paging Unit: 10-bits outer (page directory) and 10-bits inner page number with 12-bits offset for 4KB page
 - A special bit in the page directory (outer page number) indicates that this page is a 4MB page (22 bits for page offset in this case)
 - The CR3 register points to the page directory for the current process (removes memory access for page directory)

 ** If the inner page table is currently swapped our to disk, then the page directory will have an 'invalid bit' set, and the remaining 31 bits provied information on where to find the swapped out page table on the disk.

 . PAE (Page Address Extention) - for accessing physical address larger than 4GB
 - Three level paging scheme is incorporated with 32-bits linear address structure of
 1) 2-bits page directory pointer table, 2) 9-bits page directory, 3) 9-bits page table, and 4) 12-bits page offset
 - Using such three level paging scheme, 2MB page is supported (11-bits of page directory pointer table and page directory table leaves the following 21-bits for designating offsets of 2MB (i.e., instead of 4MB big page before))
 - By extending the size of each entry in page directory and page table, 20-bits of base address in two level page has been extended to become 24-bits, which can address 64GB physical memory space

 ** PAE is supported by both Linux and Mac OS X but not by 32-bit versions of Windows OS.


- x86-64 Architecture
 * This architecture currently provides a 48-bits virtual address (not fully 64 bit address - 16 E(xa)B address) with support for page sizes 4KB, 2MB, or 1GB using 4 levels of paging hierarchy

 . Since the addressing scheme can use PAE,
  virtual address uses 48-bits but supports for 52-bits of physical address space (corresponds to 4,096 TB physical memory)

 ** Note that the hierarchical structure of page table is to minimize the size of page table to be kept for each process




4. Safe Sequence의 의미를 설명하고, Banker's Algorithm을 통해 Safe Sequence를 검출하는 방법에 대해 예를 들어 설명


-Banker's Algorithm

* Definitions
 . m: the number of resource tyeps
 . int Available[m]: Available[j]=k means that k instance of Rj (resource type) is avaliable
 . n: the number of processes running
 . int Max[n][m]: Max[i][j]=k neans the process Pi may request the instances of R, as many as k.
 . int Allocation[n][m]: Allocation[i][j]=k means the process Pi is currently allocated k instances of the resource Rj
 . int Need[n][m]: Need[i][j]=k means the process Pi may meed k more instances of resources type Rj (i.e. Need[i][j] = Max[i][j] - Allocation[i][j])
 . Allocationi, Maxj, and Needi are the i-th row vector (for i-th process) of Allocation, Max, and Need matrix, respectively.
 . For two vectors X and X, Y <= Y means that X[i] <= Y[i], for all i.


* Safty Check Algorithm
 1) define Work = Available and Finish[i] = false, for i=0, 1, ..., n-1 (the number of processes)
 2) find i such that Finish[i] == false and Needi<=Worki at the same time. If so such i exists, GoTo4. (find process to be allocated)
 3) Worki = Worki + Allocationi, Finish[i]=true, and GoTo 2. (assume finished)
 4) if Finish[i] == true for all i, then the system is in a safe state (with safe sequence of Pi's found in 2 in order)


* Resource-Request Algorithm
 Let Requesti be the request vector for the process Pi. When a request for resources is made by Pi,
 1) check Requesti <= Needi, if failure, raise an error. (check maximum request bound)
 2) Check Requesti <= Available, GoTo 3. If failure, Pi must wait. (check request can be allocated)
 3) Change Available -= Requesti, Allocationi += Requesti, and Needi -= Requesti (pretend the allocation is granted)
  Then run the safty check algorithm to grant the request or to wait the request.


* An illustrative example
 . Suppose that, at time T0, the right side of system is given.
 . The system is currently safe with safe sequence <P1, P3, P4, P2, P0>
 . At time T1, suppose that Request1 = (1, 0, 2) is given.
  The request is less than Max1, and Available.
 . Safety check algorithm is done on.

             Allocation     Max    Available     Need
                ABC         ABC       ABC         ABC
   P0          010          753       332          743
   P1          200          322                     122
   P2          302          902                     600
   P3          211          222                     011
   P4          002          433                     431

             Allocation     Need     Available
                ABC          ABC        ABC
   P0          010          743         230
   P1          302          020
   P2          302          600
   P3          211          011
   P4          002          431

  gives a safe sequence <P1, P3, P4, P0, P2> and thus the request is willing to be granted.



5. 멀티코어 프로세서에서 프로세스 Pre-emption 시 Cache Inconsistency (Invalition) 문제와 Process Affinity 방법에 대해서







6. Windows XP OS의 스케쥴러 특징





7. Segmentation을 통한 OS의 메모리 관리를 설명하고, 이를 통해 얻을 수 있는 이점을 기술

* A logical address of a process is a collection of segments (sub-routines, functions, stack amounts, etc.) , which may have their own respective segment base (segment number) and offset (within limit register bound).

 . In case of C compiler, the generated segments are 1) the code, 2) global variables, 3) the heap, 4) the stacks of each thread, and 5) the standard libraries (i.e., different memory area - stack, data, heap, code)
 . The loader (or linker) would take all these segments and assign them segment numbers (which will be used by logical address)

* Address binding with segmentation is supported by hardware using the segment table,
 which is an array of base-limit register pairs for each segment.
 . By using separate base registers, segmentation can use non-contiguous memory for a process
 . The base-limit register usage may requires 'compaction' on the basis of segment (for the contiguous allocation for each segment)






8. Demand Paging 기법에서 page replacement 방법이 중요한 이유를 설명하고 Second Chance 알고리즘과 Enhanced Second Chance 알고리즘에 대해 기술

* Windows uses demand paging with clustering, meaning they page in multiple pages whenever a page fault occurs.
 . Working set minimum and maximum are normally set at 50 and 345 pages, respectively
 . If a page fault occurs and the process is below their maximum (~1.3MB), additional pages are allocated.
 Otherwise some pages from this process most be replaced, using a local replacement algorithm.

* If the amount of free frames falls below the allowable threshols, then working set trimming occurs,
taking frames away from any processes which are above their minimum, until all are at their minimums.
 Then additional frames can be allocated to processes that need them.

* Page replacement algorithm (selecting victims) depends on the type of processor
 . single processor x86 - a variation of second-chance algorithm is used
 . alpha or multiprocessor - a variation of FIFO is used
                                  (beacuse clearing reference its require invalidating entires in the TLB on other processors - expensive)


=====================================
- Basic Concept
* The idea of demand paging is that when a process is swapped in, the swapper (or page) loads only a portion of pages that is expected to be needed (right away)
 . Pages that are not loaded into memory are marked as invalid in the page table (using invalid bit)
 . If a page is needed that was not originally loaded up, then a page fault trap is generated, which is handled in septs of:
  1) requested memory address is checked whether it is valid or not
  2) when the reference is invalid, OS preenpt the system for handling the page fault trap
  3) OS checks available memory frames from a free-frame list (for allocating a page or swapping in a page)
  4) a disk operation is scheduled to bring in the necessary from disk (I/O blocking is occured for the current process)
  5) when the I/O completes, the process's page table is updated with the new frame number and the valid bit is set
  6) the instruction that caused the page fault is restarted from the beginning



* Pure Demand Paging - NO pages are swapped in for a process until they are requested by page faults (an extreme case)
 . In theory each instruction could generate multiple page faults, but this is very rare in practice because of the locality of reference
 . The hardware supporting virtual memory is the same as for paging and swapping


 - Performance of Demand Paging
* Page fault slowdown the system (swapping goes get data from disk), and thus its effect needs to be analyzed
 . suppose that a normal memory access requires 2ns (500MHz access) and serving page fault 80us (40,000 times of normal access)
  With a page fault rate of p, the effective access time will be

     E = (l-p) * (2) + p*(80000) = 2 + 79,998*p

 . With page fault rate of 0.001 (once at every 1,000 times memory access), the effective access time drops to 82ns (41 times)
 In order to keep the slowdowm factor less than 10%, the page fault rate must be less than 0.0000025 (once in 399.990 accesses)
 . Swap space is generally faster than the regular file system, because it does not have to go through the whole directory structure.
 For this reason, some systems transfer an entire process from the file system to swap space before starting up the process.
 . Some systems use demand paging directly from the file systme for program code, and to reserve the swap space for data segments.
 This is because the program code never changes and hence does not have to be stored on page operation (Solaris and BSD Unix)



9. TLB (Translation Lookaside Buffer)를 가지는 paging 시스템에서 Virtual Address를 사용하는 CPU가 특정 메모리 번지의 데이터를 접근하는 과정을 설명하세요 (단, 빠른 데이터 접근을 위해 해당 시스템은 data cache를 사용한다고 가정함)

=======================
Data Access Mechanism

- virtual address space is translated to physical address space to access data

* TLB is checked first to find whether the requested data is in the memory or not
 . 64 items (128 for instruction) for data TLB (level 1) with 512 shared entreis of Level 2 TLB in Intel I7
* note that TLB is shared by multiple cores
 . TLB miss requires two times of memory access for page translation via page table
* TLB/cache miss and corruption
 . internal fragmentation of cache lines and pages make data loaded in TLB/cache useless
 . cache alignment (starting data address coincide with cache line size) and data allocation within a page (or a number of pages) need to be controlled in application program

